# -*- coding: utf-8 -*-
"""lab10-340.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_ym5lZc3ql_xfxVCJ1zA-yCTUt9EJu9R
"""

!pip install wget

import os

dataset_url = 'https://www.crcv.ucf.edu/data/UCF101/UCF101.rar'
dataset_dir = '/content/UCF-101'

os.makedirs(dataset_dir, exist_ok=True)
!curl --insecure -o /content/UCF-101/UCF101.rar 'https://www.crcv.ucf.edu/data/UCF101/UCF101.rar'

!apt-get install unrar
!unrar x /content/UCF-101/UCF101.rar /content/UCF-101/

import shutil
import random

SELECTED_CLASSES = ['Basketball', 'Biking', 'PlayingGuitar', 'Typing', 'JumpRope']
VIDEOS_PER_CLASS = 10
DEST_DIR = '/content/UCF101_subset'

os.makedirs(DEST_DIR, exist_ok=True)

for cls in SELECTED_CLASSES:
    class_path = os.path.join('/content/UCF-101/UCF-101', cls)
    dest_class_path = os.path.join(DEST_DIR, cls)
    os.makedirs(dest_class_path, exist_ok=True)

    selected = random.sample(os.listdir(class_path), VIDEOS_PER_CLASS)
    for video in selected:
        shutil.copy(os.path.join(class_path, video), dest_class_path)

!pip install tensorflow

import cv2
import numpy as np

def extract_frames(video_path, frame_interval=5, frame_size=(224, 224), max_frames=16):
    frames = []
    cap = cv2.VideoCapture(video_path)
    frame_count = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        if frame_count % frame_interval == 0:
            frame = cv2.resize(frame, frame_size)
            frames.append(frame)
        frame_count += 1
        if len(frames) == max_frames:
            break
    cap.release()
    return np.array(frames)


video_path = '/content/UCF-101/UCF-101/Basketball/v_Basketball_g01_c01.avi'
frames = extract_frames(video_path)
print(f"Extracted frames shape: {frames.shape}")


from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical

def load_dataset(DEST_DIR, selected_classes, frame_size=(224, 224), max_frames=16):
    X = []
    y = []
    class_labels = {cls: idx for idx, cls in enumerate(selected_classes)}

    for cls in selected_classes:
        class_path = os.path.join(DEST_DIR, cls)
        for video_file in os.listdir(class_path):
            video_path = os.path.join(class_path, video_file)
            frames = extract_frames(video_path, frame_size=frame_size, max_frames=max_frames)
            if frames.shape[0] == max_frames:
                X.append(frames)
                y.append(class_labels[cls])

    X = np.array(X)
    y = np.array(y)
    y = to_categorical(y, num_classes=len(selected_classes))
    return X, y

X, y = load_dataset(DEST_DIR, SELECTED_CLASSES)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import LSTM, Conv3D, MaxPooling3D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ModelCheckpoint
from sklearn.utils import class_weight
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import matplotlib.pyplot as plt
import numpy as np

datagen = ImageDataGenerator(
    rotation_range=30,
    width_shift_range=0.3,
    height_shift_range=0.3,
    shear_range=0.3,
    zoom_range=0.3,
    horizontal_flip=True,
    fill_mode='nearest'
)

def augment_video_frames(frames):
    augmented_frames = []
    for frame in frames:
        augmented_frame = datagen.random_transform(frame)
        augmented_frames.append(augmented_frame)
    return np.array(augmented_frames)

X_train_augmented = np.array([augment_video_frames(video) for video in X_train])

def build_cnn_lstm_model(input_shape, num_classes):
    model = Sequential()

    model.add(Conv3D(64, (3, 3, 3), activation='relu', padding='SAME', input_shape=input_shape, kernel_regularizer='l2'))
    model.add(BatchNormalization())
    model.add(MaxPooling3D(pool_size=(2, 2, 2)))

    model.add(Conv3D(128, (3, 3, 3), activation='relu', padding='SAME', kernel_regularizer='l2'))
    model.add(BatchNormalization())
    model.add(MaxPooling3D(pool_size=(2, 2, 2)))

    model.add(Conv3D(256, (3, 3, 3), activation='relu', padding='SAME', kernel_regularizer='l2'))
    model.add(BatchNormalization())
    model.add(MaxPooling3D(pool_size=(2, 2, 2)))

    model.add(Flatten())
    model.add(Dense(512, activation='relu', kernel_regularizer='l2'))
    model.add(Dropout(0.5))

    model.add(Dense(num_classes, activation='softmax'))

    model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])

    return model

input_shape = (16, 224, 224, 3)
model = build_cnn_lstm_model(input_shape, 5)
model.summary()

y_train_labels = np.argmax(y_train, axis=1)
y_test_labels = np.argmax(y_test, axis=1)

class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train_labels), y=y_train_labels)
class_weights = dict(enumerate(class_weights))
print("Class weights:", class_weights)

checkpoint = ModelCheckpoint(
    filepath='best_model.h5',
    monitor='val_accuracy',
    mode='max',
    save_best_only=True,
    verbose=1
)

history = model.fit(
    X_train_augmented, y_train,
    epochs=100,
    batch_size=4,
    validation_data=(X_test, y_test),
    class_weight=class_weights,
    callbacks=[checkpoint]
)

print("\nLoading best model based on validation accuracy...")
best_model = load_model('best_model.h5')
loss, acc = best_model.evaluate(X_test, y_test)
print(f"Best Model Accuracy on Test Set: {acc*100:.2f}%")

from tensorflow.keras.models import load_model
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import matplotlib.pyplot as plt


best_model = load_model('best_model.h5')

y_pred = best_model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test, axis=1)

accuracy = accuracy_score(y_true, y_pred_classes)
print(f"Best Model Accuracy on Test Set: {accuracy * 100:.2f}%")

cm = confusion_matrix(y_true, y_pred_classes)
print(f"Confusion Matrix:\n{cm}")

report = classification_report(y_true, y_pred_classes, target_names=SELECTED_CLASSES)
print(f"Classification Report:\n{report}")

plt.figure(figsize=(8, 5))
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy Over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(8, 5))
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss Over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.show()