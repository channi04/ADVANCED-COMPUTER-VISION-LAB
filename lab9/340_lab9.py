# -*- coding: utf-8 -*-
"""340-lab9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h2yL9Rxmr5B0GWn71YbXiLOIJ_scpxwa
"""

import tensorflow as tf
import numpy as np
import cv2
import matplotlib.pyplot as plt
from tensorflow.keras.datasets import cifar10
from tensorflow.keras import layers, models, callbacks

# Load and preprocess CIFAR-10 dataset
(x_train, _), (x_test, _) = cifar10.load_data()
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# Convert to grayscale
x_train_gray = np.mean(x_train, axis=-1, keepdims=True)
x_test_gray = np.mean(x_test, axis=-1, keepdims=True)

# Add noise and blur
def add_noise(img):
    noise = np.random.normal(0, 0.1, img.shape)
    return np.clip(img + noise, 0., 1.)

def add_blur(img):
    return cv2.GaussianBlur(img, (5, 5), 0)

x_train_noisy = np.array([add_blur(add_noise(img)) for img in x_train_gray])
x_test_noisy = np.array([add_blur(add_noise(img)) for img in x_test_gray])

# Build deeper autoencoder
def build_autoencoder():
    input_img = layers.Input(shape=(32, 32, 1))

    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)
    x = layers.BatchNormalization()(x)
    x = layers.MaxPooling2D((2, 2), padding='same')(x)
    x = layers.Dropout(0.2)(x)

    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.MaxPooling2D((2, 2), padding='same')(x)
    x = layers.Dropout(0.2)(x)

    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.MaxPooling2D((2, 2), padding='same')(x)

    x = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.MaxPooling2D((2, 2), padding='same')(x)

    x = layers.Conv2DTranspose(256, (3, 3), activation='relu', padding='same')(x)
    x = layers.UpSampling2D((2, 2))(x)

    x = layers.Conv2DTranspose(128, (3, 3), activation='relu', padding='same')(x)
    x = layers.UpSampling2D((2, 2))(x)

    x = layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)
    x = layers.UpSampling2D((2, 2))(x)

    x = layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)
    x = layers.UpSampling2D((2, 2))(x)

    decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)

    model = models.Model(input_img, decoded)
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='mse')
    return model

autoencoder = build_autoencoder()
autoencoder.summary()

# Callbacks
checkpoint_cb = callbacks.ModelCheckpoint("best_autoencoder.keras", save_best_only=True, monitor='val_loss')

earlystop_cb = callbacks.EarlyStopping(patience=10, restore_best_weights=True, monitor='val_loss')

# Train for 100 epochs
autoencoder.fit(
    x_train_noisy, x_train_gray,
    epochs=100,
    batch_size=128,
    validation_data=(x_test_noisy, x_test_gray),
    callbacks=[checkpoint_cb, earlystop_cb]
)

# Predict restored images
restored = autoencoder.predict(x_test_noisy)

# Display original, noisy, and restored images
n = 10
plt.figure(figsize=(20, 6))
for i in range(n):
    ax = plt.subplot(3, n, i + 1)
    plt.imshow(x_test_gray[i].reshape(32, 32), cmap='gray')
    ax.set_title("Original")
    plt.axis("off")

    ax = plt.subplot(3, n, i + 1 + n)
    plt.imshow(x_test_noisy[i].reshape(32, 32), cmap='gray')
    ax.set_title("Noisy")
    plt.axis("off")

    ax = plt.subplot(3, n, i + 1 + 2 * n)
    plt.imshow(restored[i].reshape(32, 32), cmap='gray')
    ax.set_title("Restored")
    plt.axis("off")
plt.tight_layout()
plt.show()

# PSNR calculation
def psnr(y_true, y_pred):
    return tf.image.psnr(y_true, y_pred, max_val=1.0)

print("PSNR values:")
for i in range(n):
    print(psnr(x_test_gray[i], restored[i]).numpy())